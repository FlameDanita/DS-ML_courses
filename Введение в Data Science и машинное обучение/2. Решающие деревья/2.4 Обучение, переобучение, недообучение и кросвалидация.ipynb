{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from IPython.display import display\n",
    "from graphviz import Source\n",
    "from IPython.display import HTML\n",
    "style = \"<style>svg{width:0.1% !important;height:0.1% !important;</style>\"\n",
    "HTML( style )\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + \"C:\\\\Program Files (x86)\\\\graphviz2.38\\\\bin\" + os.pathsep + \"C:\\\\Program Files (x86)\\\\graphviz2.38\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv('titanic/train.csv')\n",
    "titanic_data.head()\n",
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_data.drop(['PassengerId', 'Survived', 'Name', 'Cabin', 'Ticket'], axis=1)\n",
    "y = titanic_data.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X) # избавление от строковых значений\n",
    "X = X.fillna({'Age': X.Age.median()})\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_values = range(1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_depth in max_depth_values:\n",
    "    clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "\n",
    "    temp_score_data = pd.DataFrame({'max_depth': [max_depth],\n",
    "                                    'train_score': [train_score],\n",
    "                                    'test_score': [test_score]})\n",
    "\n",
    "    scores_data = pd.concat([scores_data, temp_score_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data_long = pd.melt(scores_data, id_vars=['max_depth'], value_vars=['train_score', 'test_score'],\n",
    "                var_name='set_type', value_name='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='max_depth', y='score', hue='set_type', data=scores_data_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data = pd.DataFrame()\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "\n",
    "    mean_cross_val_score = cross_val_score(clf, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    temp_score_data = pd.DataFrame({'max_depth': [max_depth],\n",
    "                                    'train_score': [train_score],\n",
    "                                    'test_score': [test_score],\n",
    "                                    'cross_val_score': [mean_cross_val_score]})\n",
    "\n",
    "    scores_data = pd.concat([scores_data, temp_score_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data_long = pd.melt(scores_data, id_vars=['max_depth'], value_vars=['train_score', 'test_score', 'cross_val_score'],\n",
    "                var_name='set_type', value_name='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='max_depth', y='score', hue='set_type', data=scores_data_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data_long.query('set_type == \"cross_val_score\"').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X_test, y_test, cv=5).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренировка на ирисах"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Подключаем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display \n",
    "from IPython.display import HTML\n",
    "from sklearn import tree\n",
    "\n",
    "style = \"<style>svg{width:50% !important;height:30% !important;}</style>\"\n",
    "HTML(style)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем базы\n",
    "df_train = pd.read_csv('train_iris.csv', index_col=0)\n",
    "df_test = pd.read_csv(\"test_iris.csv\", index_col=0)\n",
    "\n",
    "#Удаляем ненужные столбцы и тот, который будем предсказывать:\n",
    "X_train = df_train.drop(['species'], axis=1)\n",
    "X_test = df_test.drop(['species'], axis=1)\n",
    "\n",
    "#Создаем переменную, которую предсказываем:\n",
    "y_train = df_train.species\n",
    "y_test = df_test.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем согласно условию:\n",
    "rs = np.random.seed(0)\n",
    "\n",
    "#Определяем новую базу:\n",
    "score_data = pd.DataFrame()\n",
    "\n",
    "#Определяем переменную max_depth_values:\n",
    "max_depth_values = range(1, 100)\n",
    "\n",
    "#пишем цикл для поиска оптимальной глубины и сохраняем полученные данные в новую базу:\n",
    "for max_depth in max_depth_values:\n",
    "    clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_depth, random_state=rs)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "\n",
    "    mean_cross_val_score = cross_val_score(clf, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    temp_score_data = pd.DataFrame({'max_depth': [max_depth],\n",
    "                                    'train_score': [train_score],\n",
    "                                    'test_score': [test_score],\n",
    "                                    'cross_val_score': [mean_cross_val_score]})\n",
    "\n",
    "    scores_data = pd.concat([scores_data, temp_score_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data_long = pd.melt(scores_data, id_vars=['max_depth'], value_vars=['train_score', 'test_score',],\n",
    "                var_name='set_type', value_name='score')\n",
    "scores_data_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='max_depth', y='score', hue='set_type', data=scores_data_long)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем специализированные модули Pandas и Numpy, не являющиеся частью стандартной библиотеки Python.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# а также импортируем модули Seaborn, Matplotlib и Pydotplus для работы с графикой.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pydotplus\n",
    "\n",
    "# Импортируем модуль tree из библиотеки sklearn для реализации алгоритмов решающих деревьев.\n",
    "from sklearn import tree\n",
    "\n",
    "# Импортируем модули, необходимые для визуализации дерева решений.\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "\n",
    "style = \"<style>svg{width:70% !important;height:70% !important;}</style>\"\n",
    "HTML(style)\n",
    "\n",
    "# Прописываем пути до graphviz.\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + \"C:\\Program Files (x86)\\Graphviz2.38\\bin\" \\\n",
    "                      + os.pathsep + \"C:\\Program Files (x86)\\Graphviz2.38\"\n",
    "\n",
    "# Устанавливаем размер области для построения графиков.\n",
    "sns.set(rc={'figure.figsize': (9, 6)})\n",
    "\n",
    "# Считываем тренировочный файл.\n",
    "train_iris_data = pd.read_csv('https://stepik.org/media/attachments/course/4852/train_iris.csv')\n",
    "# Считываем тестовый файл.\n",
    "test_iris_data = pd.read_csv('https://stepik.org/media/attachments/course/4852/test_iris.csv')\n",
    "\n",
    "# Отбросим колонки, не несущие важной информации для построения дерева решений.\n",
    "# Отбрасываем не только предсказываемую species, но и первую колонку, так как она содержит id каждого экземпляра (цветка), а он для построения графика не нужен.\n",
    "X_train_iris = train_iris_data.drop(['Unnamed: 0', 'species'], axis=1)\n",
    "X_test_iris = test_iris_data.drop(['Unnamed: 0', 'species'], axis=1)\n",
    "\n",
    "# Создадим переменные, которые будем предсказывать.\n",
    "y_train_iris = train_iris_data.species\n",
    "y_test_iris = test_iris_data.species\n",
    "\n",
    "# Подберем оптимальное значение глубины обучения дерева.\n",
    "# Зададим диапазон исследуемых значений.\n",
    "max_iris_depth_values = range(1, 100)\n",
    "\n",
    "# Обнулим DataFrame.\n",
    "scores_iris_data = pd.DataFrame()\n",
    "\n",
    "#  Задаем random seed.\n",
    "rs = np.random.seed(0)\n",
    "\n",
    "for max_iris_depth in max_iris_depth_values:\n",
    "    # Изменяем глубину обучения дерева по циклу от 1 до 99 с шагом 1.\n",
    "    clf_iris = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_iris_depth, random_state=rs)\n",
    "    # Обучаем дерево решений (с ограниченной глубиной) на подмножестве train.\n",
    "    clf_iris.fit(X_train_iris, y_train_iris)\n",
    "    # Записываем в отдельную переменную число правильных ответов на обученной модели дерева\n",
    "    # с ограниченной глубиной (подмножество train)\n",
    "    train_iris_score = clf_iris.score(X_train_iris, y_train_iris)\n",
    "    # Записываем в отдельную переменную число правильных ответов на обученной модели дерева\n",
    "    # с ограниченной глубиной (подмножество test)\n",
    "    test_iris_score = clf_iris.score(X_test_iris, y_test_iris)\n",
    "    # Создаем временный DataFrame.\n",
    "    temp_score_iris_data = pd.DataFrame({'max_iris_depth':[max_iris_depth],\n",
    "                                         'train_iris_score':[train_iris_score],\n",
    "                                         'test_iris_score':[test_iris_score]})\n",
    "    # Наращиваем DataFrame \"scores_iris_data\".\n",
    "    scores_iris_data = scores_iris_data.append(temp_score_iris_data)\n",
    "\n",
    "# Видоизменим DataFrame, применив метод melt().\n",
    "scores_iris_data_long = pd.melt(scores_iris_data, id_vars=['max_iris_depth'],\n",
    "                           value_vars=['train_iris_score','test_iris_score'],\n",
    "                           var_name='set_type', value_name='score')\n",
    "\n",
    "# Визуализация.\n",
    "sns.lineplot(x='max_iris_depth', y='score', hue='set_type', data=scores_iris_data_long)\n",
    "\n",
    "# Отображение графиков Matplotlib и Seaborn в PyCharm.\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тренировка на котиках и собачках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as nm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# написать про этот мем ( from sklearn.model_selecion import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6beef5ba6e6066e2eca26c3238fb752a2b2f561695d75d02aa01cbdf48771d57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
